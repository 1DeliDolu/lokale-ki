"""
Ana gÃ¶rsel analiz sÄ±nÄ±fÄ± - Yeniden dÃ¼zenlenmiÅŸ ve geliÅŸtirilmiÅŸ versiyon
"""

import torch
from PIL import Image
from transformers import AutoProcessor, BlipForConditionalGeneration
from typing import Union, List, Dict, Any, Optional
import logging

from .config import ModelConfig, AnalysisConfig
from .utils import ImageUtils, FileUtils, ProgressTracker
from .exceptions import (
    ModelLoadError, 
    ImageProcessingError, 
    GenerationError, 
    FileOperationError
)

# Logging ayarlarÄ±
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class ImageAnalyzer:
    """
    GeliÅŸmiÅŸ gÃ¶rsel analizi ve aÃ§Ä±klama Ã¼retimi sÄ±nÄ±fÄ±
    """
    
    def __init__(
        self, 
        model_config: Optional[ModelConfig] = None,
        analysis_config: Optional[AnalysisConfig] = None
    ):
        """
        Analyzer'Ä± baÅŸlat
        
        Args:
            model_config (ModelConfig, optional): Model konfigÃ¼rasyonu
            analysis_config (AnalysisConfig, optional): Analiz konfigÃ¼rasyonu
        """
        self.model_config = model_config or ModelConfig()
        self.analysis_config = analysis_config or AnalysisConfig()
        
        # Model ve processor'u yÃ¼kle
        self._load_model()
        
        logger.info(f"âœ… ImageAnalyzer baÅŸlatÄ±ldÄ± - Model: {self.model_config.model_name}")
    
    def _load_model(self) -> None:
        """Model ve processor'u yÃ¼kle"""
        try:
            logger.info(f"ðŸ¤– Model yÃ¼kleniyor: {self.model_config.model_name}")
            
            # Processor yÃ¼kle
            self.processor = AutoProcessor.from_pretrained(
                self.model_config.model_name,
                cache_dir=self.model_config.cache_dir,
                use_auth_token=self.model_config.use_auth_token
            )
            
            # Model yÃ¼kle
            self.model = BlipForConditionalGeneration.from_pretrained(
                self.model_config.model_name,
                cache_dir=self.model_config.cache_dir,
                use_auth_token=self.model_config.use_auth_token
            )
            
            # Device ayarlarÄ±
            if self.model_config.device == "auto":
                self.device = "cuda" if torch.cuda.is_available() else "cpu"
            else:
                self.device = self.model_config.device
            
            self.model.to(self.device)
            logger.info(f"ðŸ“± Device: {self.device}")
            
        except Exception as e:
            raise ModelLoadError(self.model_config.model_name, str(e))
    
    def generate_caption(
        self, 
        image: Union[str, Image.Image], 
        conditional_text: str = ""
    ) -> str:
        """
        GÃ¶rsel iÃ§in aÃ§Ä±klama Ã¼ret
        
        Args:
            image: GÃ¶rsel dosyasÄ±
            conditional_text (str): KoÅŸullu metin
            
        Returns:
            str: Ãœretilen aÃ§Ä±klama
            
        Raises:
            GenerationError: Ãœretim hatasÄ±
        """
        try:
            # GÃ¶rseli iÅŸle
            processed_image = ImageUtils.preprocess_image(
                image, 
                self.analysis_config.max_image_size
            )
            
            # Model giriÅŸi hazÄ±rla
            if conditional_text:
                inputs = self.processor(
                    images=processed_image, 
                    text=conditional_text, 
                    return_tensors="pt"
                ).to(self.device)
            else:
                inputs = self.processor(
                    images=processed_image, 
                    return_tensors="pt"
                ).to(self.device)
            
            # AÃ§Ä±klama Ã¼ret
            with torch.no_grad():
                outputs = self.model.generate(
                    **inputs,
                    max_length=self.model_config.max_length,
                    num_beams=self.model_config.num_beams,
                    do_sample=self.model_config.do_sample,
                    early_stopping=self.model_config.early_stopping,
                    temperature=self.model_config.temperature if self.model_config.do_sample else 1.0
                )
            
            # Ã‡Ä±ktÄ±yÄ± decode et
            caption = self.processor.decode(outputs[0], skip_special_tokens=True)
            
            # KoÅŸullu metni temizle
            if conditional_text:
                caption = caption.replace(conditional_text, "").strip()
            
            return caption.strip()
            
        except Exception as e:
            if isinstance(e, ImageProcessingError):
                raise
            raise GenerationError("Caption generation", str(e))
    
    def generate_title(self, image: Union[str, Image.Image]) -> str:
        """
        GÃ¶rsel iÃ§in baÅŸlÄ±k Ã¼ret
        
        Args:
            image: GÃ¶rsel dosyasÄ±
            
        Returns:
            str: Ãœretilen baÅŸlÄ±k
        """
        try:
            title = self.generate_caption(image, self.analysis_config.title_prompt)
              # BaÅŸlÄ±ÄŸÄ± formatla
            title = title.capitalize()
            if len(title) > self.analysis_config.title_max_length:
                title = title[:self.analysis_config.title_max_length] + "..."
            
            return title if title else "Untitled"
            
        except Exception as e:
            logger.warning(f"BaÅŸlÄ±k Ã¼retme hatasÄ±: {str(e)}")
            return "Untitled"
    
    def analyze_image(self, image: Union[str, Image.Image]) -> Dict[str, Any]:
        """
        GÃ¶rsel iÃ§in kapsamlÄ± analiz yap
        
        Args:
            image: GÃ¶rsel dosyasÄ±
            
        Returns:
            dict: Analiz sonucu
        """
        try:
            if image is None:
                return {
                    'title': "âŒ GÃ¶rsel yok",
                    'caption': "LÃ¼tfen bir gÃ¶rsel yÃ¼kleyin",
                    'status': "âŒ GÃ¶rsel seÃ§ilmedi",
                    'success': False,
                    'image_info': None
                }
            
            # GÃ¶rsel bilgilerini al (hata durumunda None)
            try:
                image_info = ImageUtils.get_image_info(image)
            except Exception:
                image_info = None
            
            # BaÅŸlÄ±k Ã¼ret
            title = self.generate_title(image)
            
            # AÃ§Ä±klama Ã¼ret
            caption = self.generate_caption(image, self.analysis_config.caption_prompt)
            
            logger.info(f"âœ… Analiz tamamlandÄ± - BaÅŸlÄ±k: {title}")
            
            return {
                'title': title,
                'caption': caption,
                'status': "âœ… Analiz tamamlandÄ±!",
                'success': True,
                'image_info': image_info,
                'model_info': {
                    'model_name': self.model_config.model_name,
                    'device': self.device
                }
            }
            
        except Exception as e:
            error_msg = str(e)
            logger.error(f"âŒ Analiz hatasÄ±: {error_msg}")
            return {
                'title': "âŒ Analiz hatasÄ±",
                'caption': f"Hata detayÄ±: {error_msg}",
                'status': "âŒ Ä°ÅŸlem baÅŸarÄ±sÄ±z",
                'success': False,
                'image_info': None,
                'error': error_msg
            }
    
    def save_image_with_metadata(
        self, 
        image: Union[str, Image.Image], 
        title: str, 
        caption: str,
        output_dir: Optional[str] = None
    ) -> str:
        """
        GÃ¶rseli metadata ile birlikte kaydet
        
        Args:
            image: GÃ¶rsel dosyasÄ±
            title (str): BaÅŸlÄ±k
            caption (str): AÃ§Ä±klama
            output_dir (str, optional): Ã‡Ä±ktÄ± klasÃ¶rÃ¼
            
        Returns:
            str: Ä°ÅŸlem sonucu mesajÄ±
        """
        try:
            if image is None:
                return "âŒ Kaydedilecek gÃ¶rsel yok"
            
            # Ã‡Ä±ktÄ± klasÃ¶rÃ¼nÃ¼ belirle
            if output_dir is None:
                output_dir = self.analysis_config.output_directory
            
            # KlasÃ¶rÃ¼ oluÅŸtur
            FileUtils.ensure_directory(output_dir)
            
            # GÃ¶rseli PIL Image'e Ã§evir
            if isinstance(image, str):
                pil_image = Image.open(image).convert('RGB')
            else:
                pil_image = ImageUtils.preprocess_image(image)
            
            # Dosya adÄ±nÄ± oluÅŸtur
            safe_title = FileUtils.create_safe_filename(title)
            file_path = FileUtils.get_unique_filepath(
                f"{output_dir}/{safe_title}.jpg"
            )
              # GÃ¶rseli kaydet
            pil_image.save(
                file_path, 
                self.analysis_config.output_format,
                quality=self.analysis_config.image_quality,
                optimize=True
            )
            
            # Metadata kaydet
            if self.analysis_config.save_metadata:
                try:
                    image_info = ImageUtils.get_image_info(pil_image)
                    additional_info = {
                        'Original Size': f"{image_info['width']}x{image_info['height']}",
                        'File Format': image_info['format'],
                        'Device': self.device
                    }
                except Exception:
                    # Image info alÄ±namazsa basit bilgi kaydet
                    additional_info = {
                        'Device': self.device,
                        'Processing': 'Successful'
                    }
                
                FileUtils.save_metadata(
                    file_path, 
                    title, 
                    caption, 
                    self.model_config.model_name,
                    additional_info
                )
            
            logger.info(f"ðŸ’¾ GÃ¶rsel kaydedildi: {file_path}")
            return f"âœ… GÃ¶rsel kaydedildi: {file_path}"
            
        except Exception as e:
            error_msg = f"Kaydetme hatasÄ±: {str(e)}"
            logger.error(f"âŒ {error_msg}")
            return f"âŒ {error_msg}"
    
    def batch_analyze(
        self, 
        image_paths: List[str],
        save_results: bool = False
    ) -> List[Dict[str, Any]]:
        """
        Birden fazla gÃ¶rseli toplu analiz et
        
        Args:
            image_paths (List[str]): GÃ¶rsel dosya yollarÄ±
            save_results (bool): SonuÃ§larÄ± kaydet
            
        Returns:
            List[dict]: Analiz sonuÃ§larÄ±
        """
        results = []
        
        # Ä°lerleme takibi
        if self.analysis_config.show_progress:
            progress = ProgressTracker(len(image_paths), "GÃ¶rsel Analizi")
        
        for i, image_path in enumerate(image_paths):
            try:
                # Analiz yap
                result = self.analyze_image(image_path)
                result['file_path'] = image_path
                
                # Kaydetme
                if save_results and result['success']:
                    save_result = self.save_image_with_metadata(
                        image_path,
                        result['title'],
                        result['caption']
                    )
                    result['save_result'] = save_result
                
                results.append(result)
                
                # Ä°lerleme gÃ¼ncelle
                if self.analysis_config.show_progress:
                    progress.update()
                
            except Exception as e:
                error_result = {
                    'file_path': image_path,
                    'title': "âŒ Hata",
                    'caption': str(e),
                    'status': "âŒ BaÅŸarÄ±sÄ±z",
                    'success': False,
                    'error': str(e)
                }
                results.append(error_result)
                
                logger.error(f"âŒ Hata: {image_path} - {str(e)}")
                
                if self.analysis_config.show_progress:
                    progress.update()
        
        return results
    
    def get_model_info(self) -> Dict[str, Any]:
        """
        Model bilgilerini al
        
        Returns:
            dict: Model bilgileri
        """
        return {
            'model_name': self.model_config.model_name,
            'device': self.device,
            'cuda_available': torch.cuda.is_available(),
            'model_config': self.model_config.to_dict(),
            'analysis_config': self.analysis_config.to_dict()
        }

# Geriye uyumluluk iÃ§in eski sÄ±nÄ±f adÄ±
ImageAnalyzer_Legacy = ImageAnalyzer