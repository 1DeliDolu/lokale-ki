import gradio as gr
import numpy as np
import os
from PIL import Image
from transformers import AutoProcessor, BlipForConditionalGeneration
import torch

# Modeli ve iÅŸlemciyi yÃ¼kle
print("ğŸ¤– Model yÃ¼kleniyor...")
processor = AutoProcessor.from_pretrained("Salesforce/blip-image-captioning-base")
model = BlipForConditionalGeneration.from_pretrained("Salesforce/blip-image-captioning-base")
print("âœ… Model baÅŸarÄ±yla yÃ¼klendi!")

def generate_caption_and_title(input_image: np.ndarray):
    """
    YÃ¼klenen gÃ¶rsel iÃ§in aÃ§Ä±klama ve baÅŸlÄ±k Ã¼retir
    """
    try:
        # NumPy array'ini PIL Image'e Ã§evir
        raw_image = Image.fromarray(input_image).convert('RGB')
        
        # 1. Genel aÃ§Ä±klama iÃ§in iÅŸlem
        inputs = processor(images=raw_image, text="a photography of", return_tensors="pt")
        
        # AÃ§Ä±klama Ã¼ret
        with torch.no_grad():
            outputs = model.generate(**inputs, max_length=50, num_beams=5)
        
        caption = processor.decode(outputs[0], skip_special_tokens=True)
        
        # 2. BaÅŸlÄ±k iÃ§in daha kÄ±sa bir aÃ§Ä±klama
        title_inputs = processor(images=raw_image, text="this is", return_tensors="pt")
        
        with torch.no_grad():
            title_outputs = model.generate(**title_inputs, max_length=20, num_beams=3)
        
        title = processor.decode(title_outputs[0], skip_special_tokens=True)
        
        # SonuÃ§larÄ± temizle ve formatla
        caption = caption.replace("a photography of", "").strip()
        title = title.replace("this is", "").strip()
        
        # BaÅŸlÄ±ÄŸÄ± bÃ¼yÃ¼k harfle baÅŸlat
        title = title.capitalize()
        
        return title, caption, "âœ… Analiz tamamlandÄ±!"
        
    except Exception as e:
        return "âŒ Hata oluÅŸtu", f"Hata: {str(e)}", "âŒ Analiz baÅŸarÄ±sÄ±z"

def save_image_with_caption(input_image: np.ndarray, title: str, caption: str):
    """
    GÃ¶rseli aÃ§Ä±klama ve baÅŸlÄ±kla birlikte kaydet
    """
    try:
        # Ã‡Ä±ktÄ± klasÃ¶rÃ¼nÃ¼ oluÅŸtur
        output_dir = "captioned_images"
        os.makedirs(output_dir, exist_ok=True)
        
        # PIL Image'e Ã§evir
        image = Image.fromarray(input_image)
        
        # Dosya adÄ±nÄ± gÃ¼venli hale getir
        safe_title = "".join(c for c in title if c.isalnum() or c in (' ', '-', '_')).rstrip()
        safe_title = safe_title.replace(' ', '_')
        
        # Dosya yolu
        file_path = os.path.join(output_dir, f"{safe_title}.jpg")
        
        # GÃ¶rseli kaydet
        image.save(file_path, "JPEG", quality=95)
        
        # AÃ§Ä±klama dosyasÄ±nÄ± kaydet
        caption_file = os.path.join(output_dir, f"{safe_title}_caption.txt")
        with open(caption_file, 'w', encoding='utf-8') as f:
            f.write(f"BaÅŸlÄ±k: {title}\n")
            f.write(f"AÃ§Ä±klama: {caption}\n")
        
        return f"âœ… GÃ¶rsel kaydedildi: {file_path}"
        
    except Exception as e:
        return f"âŒ Kaydetme hatasÄ±: {str(e)}"

# Gradio arayÃ¼zÃ¼
with gr.Blocks(title="ğŸ¤– AI GÃ¶rsel AÃ§Ä±klayÄ±cÄ± ve BaÅŸlÄ±k Ãœreteci", theme=gr.themes.Soft()) as demo:
    
    gr.Markdown("""
    # ğŸ–¼ï¸ Yapay Zeka GÃ¶rsel AÃ§Ä±klayÄ±cÄ±
    
    Bu uygulama ile:
    - ğŸ“¸ GÃ¶rsellerinizi yÃ¼kleyebilir
    - ğŸ·ï¸ Otomatik baÅŸlÄ±k Ã¼retebilir  
    - ğŸ“ DetaylÄ± aÃ§Ä±klama alabilir
    - ğŸ’¾ SonuÃ§larÄ± kaydedebilirsiniz
    
    **NasÄ±l kullanÄ±lÄ±r:** AÅŸaÄŸÄ±dan bir gÃ¶rsel yÃ¼kleyin ve "Analiz Et" butonuna tÄ±klayÄ±n!
    """)
    
    with gr.Row():
        with gr.Column(scale=1):
            # GÃ¶rsel yÃ¼kleme alanÄ±
            image_input = gr.Image(
                type="numpy",
                label="ğŸ“¸ GÃ¶rsel YÃ¼kle",
                height=400
            )
            
            # Analiz butonu
            analyze_btn = gr.Button(
                "ğŸ” Analiz Et", 
                variant="primary",
                size="lg"
            )
        
        with gr.Column(scale=1):
            # SonuÃ§ alanlarÄ±
            title_output = gr.Textbox(
                label="ğŸ·ï¸ Ãœretilen BaÅŸlÄ±k",
                placeholder="BaÅŸlÄ±k burada gÃ¶rÃ¼necek...",
                interactive=True
            )
            
            caption_output = gr.Textbox(
                label="ğŸ“ GÃ¶rsel AÃ§Ä±klamasÄ±",
                placeholder="AÃ§Ä±klama burada gÃ¶rÃ¼necek...",
                lines=4,
                interactive=True
            )
            
            status_output = gr.Textbox(
                label="ğŸ“Š Durum",
                placeholder="Durumu gÃ¶rÃ¼ntÃ¼ler..."
            )
            
            # Kaydetme butonu
            save_btn = gr.Button(
                "ğŸ’¾ Kaydet",
                variant="secondary"
            )
            
            save_status = gr.Textbox(
                label="ğŸ’¾ Kaydetme Durumu",
                placeholder="Kaydetme sonucu burada gÃ¶rÃ¼necek..."
            )
    
    # Ã–rnek gÃ¶rseller
    gr.Markdown("### ğŸ“‹ Ã–rnek GÃ¶rseller")
    gr.Examples(
        examples=[
            ["example_images/cat.jpg"] if os.path.exists("example_images/cat.jpg") else None,
            ["example_images/landscape.jpg"] if os.path.exists("example_images/landscape.jpg") else None,
        ],
        inputs=image_input,
        label="Ã–rnek gÃ¶rselleri deneyin"
    )
    
    # Event handlers
    analyze_btn.click(
        fn=generate_caption_and_title,
        inputs=image_input,
        outputs=[title_output, caption_output, status_output]
    )
    
    save_btn.click(
        fn=save_image_with_caption,
        inputs=[image_input, title_output, caption_output],
        outputs=save_status
    )
    
    # Footer
    gr.Markdown("""
    ---
    ğŸ’¡ **Ä°pucu:** SonuÃ§larÄ± beÄŸenmediyseniz, baÅŸlÄ±k ve aÃ§Ä±klama kutularÄ±nÄ± dÃ¼zenleyebilir, 
    ardÄ±ndan "Kaydet" butonuna tÄ±klayabilirsiniz.
    
    ğŸ”§ **KullanÄ±lan Model:** Salesforce/blip-image-captioning-base
    """)

# UygulamayÄ± baÅŸlat
if __name__ == "__main__":
    print("ğŸš€ Gradio uygulamasÄ± baÅŸlatÄ±lÄ±yor...")
    demo.launch(
        server_name="0.0.0.0",
        server_port=7860,
        share=False,
        debug=True
    )